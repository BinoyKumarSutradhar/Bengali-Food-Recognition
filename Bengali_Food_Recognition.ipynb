{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bengali Food Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BinoyKumarSutradhar/Bengali-Food-Recognition/blob/main/Bengali_Food_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linking to drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# drive.mount('/content/drive/MyD')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBitq_UdRBSH",
        "outputId": "b3570e1f-8586-4175-8396-ee1313a0b214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "#from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "W5WdMcgIG5BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ Testing Purpose ##################\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "temp = '/content/drive/MyDrive/Bengali Food Recognition/3282_Images_Serialized/1.jpg'\n",
        "# temp = '1.jpg'\n",
        "x = Image.open(temp)\n",
        "x = np.array(x)\n",
        "\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZr0X1xLRHRb",
        "outputId": "ae3c50c6-c55a-44f7-df84-e2e9adce3658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l6dIzVInH2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294ebc77-a546-4f26-bac1-418d52458087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4554, 64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "train_Y = []\n",
        "# z = Image.open(\"/content/drive/MyDrive/Bengali Food Recognition/3282_Images_Serialized/1.jpg\")\n",
        "# z = np.array(z)\n",
        "train_X = np.zeros([4554 , 64,64,3], dtype = float)\n",
        "# train_X = np.array(train_X)\n",
        "# z = np.zeros([32,32,3]).shape\n",
        "tempstr = \"/content/drive/MyDrive/Bengali Food Recognition/data/\"\n",
        "for i in range(1,832,1):\n",
        "  temp = tempstr + \"img_test_biriyani/\"+ str(i) +'.jpg'\n",
        "  x = Image.open(temp)\n",
        "  x = np.array(x)\n",
        "  train_X[i-1] = x\n",
        "for i in range(1,535,1):\n",
        "  temp = tempstr + \"img_test_illish/\"+ str(i) +'.jpg'\n",
        "  x = Image.open(temp)\n",
        "  x = np.array(x)\n",
        "  train_X[i+832-1] = x\n",
        "for i in range(1,1859,1):\n",
        "  temp = tempstr + \"img_test_misty/\"+ str(i) +'.jpg'\n",
        "  x = Image.open(temp)\n",
        "  x = np.array(x)\n",
        "  train_X[i+1367-1] = x\n",
        "for i in range(1,696,1):\n",
        "  temp = tempstr + \"img_test_pitha/\"+ str(i) +'.jpg'\n",
        "  x = Image.open(temp)\n",
        "  x = np.array(x)\n",
        "  train_X[i+3226-1] = x\n",
        "for i in range(1,632,1):\n",
        "  temp = tempstr + \"img_test_ruti/\"+ str(i) +'.jpg'\n",
        "  x = Image.open(temp)\n",
        "  x = np.array(x)\n",
        "  train_X[i+3922-1] = x\n",
        "  \n",
        "print(train_X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############# Previous Version  ###############################\n",
        "train_Y = []\n",
        "# z = Image.open(\"/content/drive/MyDrive/Bengali Food Recognition/3282_Images_Serialized/1.jpg\")\n",
        "# z = np.array(z)\n",
        "train_X = np.zeros([3283 , 32,32,3], dtype = float)\n",
        "# train_X = np.array(train_X)\n",
        "z = np.zeros([32,32,3]).shape\n",
        "tempstr = \"/content/drive/MyDrive/Bengali Food Recognition/3282_Images_Serialized/\"\n",
        "for i in range(1,3283,1):\n",
        "  temp = tempstr + str(i) +'.jpg'\n",
        "  x = Image.open(temp)\n",
        "  x = np.array(x)\n",
        "  if z != x.shape:\n",
        "    print(i)\n",
        "  else:\n",
        "    train_X[i-1] = x\n",
        "  \n",
        "print(train_X.shape)\n",
        "\n",
        "# train_x=train_X.astype('float32')\n",
        "# test_X=test_X.astype('float32')\n",
        " \n",
        "# train_X=train_X/255.0\n",
        "# test_X=test_X/255.0"
      ],
      "metadata": {
        "id": "a3dSfrSrHqVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e1cb65-f441-4438-9e38-3ce72dad21b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "358\n",
            "1281\n",
            "(3283, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# train_X[357] = train_X[356]\n",
        "# train_X[1280] = train_X[1281]\n",
        "# train_X[3282] = train_X[3281]\n",
        "train_Y = np.zeros(4554, dtype = int)\n",
        "train_X=train_X/255.0\n",
        "for i in range (0,832):\n",
        "  train_Y[i] = 0\n",
        "for i in range(832,1367):\n",
        "  train_Y[i] = 1\n",
        "for i in range(1367,3226):\n",
        "  train_Y[i] = 2\n",
        "for i in range(3226,3922):\n",
        "  train_Y[i] = 3\n",
        "for i in range(3922,4554):\n",
        "  train_Y[i] = 4\n",
        "# train_Y = np.array(train_Y)\n",
        "\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.1, random_state=42)\n",
        "\n",
        "train_Y=np_utils.to_categorical(train_Y)\n",
        "test_Y=np_utils.to_categorical(test_Y)\n",
        "# print(test_Y)\n",
        "num_classes=test_Y.shape[1]\n"
      ],
      "metadata": {
        "id": "-kxmPkMpHvF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),input_shape=(64,64,3),padding='same',activation='relu',kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "kLIJEQOaH0uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd=SGD(learning_rate=0.01,momentum=0.9,decay=(0.05/25),nesterov=False)\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "  optimizer=sgd,\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VVg_-znSICfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################  Updated model  ################################\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(64, 64, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "# compile model\n",
        "# opt = SGD(lr=0.001, momentum=0.9)\n",
        "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "sgd=SGD(learning_rate=0.001,momentum=0.9,decay=(0.05/25),nesterov=False)\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "  optimizer=sgd,\n",
        "  metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "WPDgGXWQD7Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJnYwWODIHVL",
        "outputId": "7271fcbf-2c89-484a-ea7b-c6e010db5ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1048704   \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,338,661\n",
            "Trainable params: 1,337,509\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_Y, validation_data= (test_X, test_Y), epochs= 200, batch_size= 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwKcR2LXIhpa",
        "outputId": "31dde20e-62dd-42df-dfb3-a16577f568f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 6s 69ms/step - loss: 2.1628 - accuracy: 0.3087 - val_loss: 1.8403 - val_accuracy: 0.3838\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.6080 - accuracy: 0.4417 - val_loss: 2.3342 - val_accuracy: 0.3860\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.3847 - accuracy: 0.5024 - val_loss: 2.0421 - val_accuracy: 0.3728\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 1.2457 - accuracy: 0.5420 - val_loss: 1.6034 - val_accuracy: 0.4057\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.1644 - accuracy: 0.5708 - val_loss: 1.3506 - val_accuracy: 0.4561\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 1.1451 - accuracy: 0.5793 - val_loss: 1.1268 - val_accuracy: 0.5811\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 1.0969 - accuracy: 0.5947 - val_loss: 1.0889 - val_accuracy: 0.5987\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0889 - accuracy: 0.5976 - val_loss: 1.0794 - val_accuracy: 0.6053\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0455 - accuracy: 0.6088 - val_loss: 1.1003 - val_accuracy: 0.5965\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0392 - accuracy: 0.6093 - val_loss: 1.0660 - val_accuracy: 0.6228\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0095 - accuracy: 0.6213 - val_loss: 1.0541 - val_accuracy: 0.6272\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9744 - accuracy: 0.6384 - val_loss: 1.1076 - val_accuracy: 0.6272\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9584 - accuracy: 0.6388 - val_loss: 1.0883 - val_accuracy: 0.6447\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 0.9475 - accuracy: 0.6457 - val_loss: 1.0873 - val_accuracy: 0.6250\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9708 - accuracy: 0.6325 - val_loss: 1.3179 - val_accuracy: 0.5482\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.1412 - accuracy: 0.5788 - val_loss: 1.3251 - val_accuracy: 0.5833\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0613 - accuracy: 0.5979 - val_loss: 1.1963 - val_accuracy: 0.5965\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0128 - accuracy: 0.6210 - val_loss: 1.2059 - val_accuracy: 0.5965\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0682 - accuracy: 0.5952 - val_loss: 1.2060 - val_accuracy: 0.5921\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.9990 - accuracy: 0.6098 - val_loss: 1.3160 - val_accuracy: 0.5811\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9741 - accuracy: 0.6371 - val_loss: 1.1781 - val_accuracy: 0.6053\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9392 - accuracy: 0.6479 - val_loss: 1.1652 - val_accuracy: 0.6075\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9693 - accuracy: 0.6342 - val_loss: 1.0837 - val_accuracy: 0.6206\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9409 - accuracy: 0.6388 - val_loss: 1.0846 - val_accuracy: 0.6316\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9277 - accuracy: 0.6554 - val_loss: 1.0695 - val_accuracy: 0.6425\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9247 - accuracy: 0.6467 - val_loss: 1.1050 - val_accuracy: 0.6491\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8939 - accuracy: 0.6611 - val_loss: 1.1230 - val_accuracy: 0.6228\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9010 - accuracy: 0.6542 - val_loss: 1.1443 - val_accuracy: 0.6272\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 1.0907 - accuracy: 0.5881 - val_loss: 1.3048 - val_accuracy: 0.5526\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9716 - accuracy: 0.6271 - val_loss: 1.2192 - val_accuracy: 0.5987\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9427 - accuracy: 0.6391 - val_loss: 1.1389 - val_accuracy: 0.6075\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9189 - accuracy: 0.6459 - val_loss: 1.1003 - val_accuracy: 0.6250\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9101 - accuracy: 0.6571 - val_loss: 1.0971 - val_accuracy: 0.6382\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9109 - accuracy: 0.6481 - val_loss: 1.1113 - val_accuracy: 0.6338\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8958 - accuracy: 0.6615 - val_loss: 1.1222 - val_accuracy: 0.6338\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8972 - accuracy: 0.6642 - val_loss: 1.1364 - val_accuracy: 0.6250\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8727 - accuracy: 0.6708 - val_loss: 1.1387 - val_accuracy: 0.6250\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8778 - accuracy: 0.6593 - val_loss: 1.1505 - val_accuracy: 0.6118\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9353 - accuracy: 0.6408 - val_loss: 1.1730 - val_accuracy: 0.6184\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.9252 - accuracy: 0.6386 - val_loss: 1.1117 - val_accuracy: 0.6491\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8974 - accuracy: 0.6581 - val_loss: 1.1131 - val_accuracy: 0.6316\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8753 - accuracy: 0.6672 - val_loss: 1.1571 - val_accuracy: 0.6272\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8730 - accuracy: 0.6664 - val_loss: 1.1485 - val_accuracy: 0.6491\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8696 - accuracy: 0.6679 - val_loss: 1.1639 - val_accuracy: 0.6294\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8731 - accuracy: 0.6684 - val_loss: 1.1572 - val_accuracy: 0.6250\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8706 - accuracy: 0.6650 - val_loss: 1.1508 - val_accuracy: 0.6382\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8585 - accuracy: 0.6681 - val_loss: 1.1956 - val_accuracy: 0.6316\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8576 - accuracy: 0.6686 - val_loss: 1.1679 - val_accuracy: 0.6425\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8461 - accuracy: 0.6818 - val_loss: 1.1490 - val_accuracy: 0.6316\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8574 - accuracy: 0.6713 - val_loss: 1.1371 - val_accuracy: 0.6250\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8377 - accuracy: 0.6886 - val_loss: 1.1077 - val_accuracy: 0.6469\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8365 - accuracy: 0.6859 - val_loss: 1.1360 - val_accuracy: 0.6294\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8582 - accuracy: 0.6703 - val_loss: 1.1352 - val_accuracy: 0.6404\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8575 - accuracy: 0.6791 - val_loss: 1.1215 - val_accuracy: 0.6513\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8538 - accuracy: 0.6767 - val_loss: 1.1187 - val_accuracy: 0.6338\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8468 - accuracy: 0.6791 - val_loss: 1.1100 - val_accuracy: 0.6447\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8329 - accuracy: 0.6881 - val_loss: 1.1055 - val_accuracy: 0.6491\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8394 - accuracy: 0.6762 - val_loss: 1.0794 - val_accuracy: 0.6469\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8407 - accuracy: 0.6837 - val_loss: 1.0361 - val_accuracy: 0.6382\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8373 - accuracy: 0.6794 - val_loss: 1.0220 - val_accuracy: 0.6579\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8158 - accuracy: 0.6906 - val_loss: 1.0406 - val_accuracy: 0.6425\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8146 - accuracy: 0.6918 - val_loss: 1.0805 - val_accuracy: 0.6184\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8151 - accuracy: 0.6918 - val_loss: 1.0673 - val_accuracy: 0.6360\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8233 - accuracy: 0.6877 - val_loss: 1.0397 - val_accuracy: 0.6557\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8317 - accuracy: 0.6891 - val_loss: 1.0282 - val_accuracy: 0.6404\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8410 - accuracy: 0.6837 - val_loss: 1.0065 - val_accuracy: 0.6623\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8235 - accuracy: 0.6864 - val_loss: 1.0135 - val_accuracy: 0.6601\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8090 - accuracy: 0.6955 - val_loss: 1.0045 - val_accuracy: 0.6557\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8051 - accuracy: 0.6925 - val_loss: 1.0306 - val_accuracy: 0.6382\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8064 - accuracy: 0.6935 - val_loss: 1.0695 - val_accuracy: 0.6316\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8147 - accuracy: 0.6901 - val_loss: 1.0947 - val_accuracy: 0.6250\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8077 - accuracy: 0.6957 - val_loss: 1.0553 - val_accuracy: 0.6294\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8246 - accuracy: 0.6811 - val_loss: 1.1443 - val_accuracy: 0.5789\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8002 - accuracy: 0.6962 - val_loss: 1.0720 - val_accuracy: 0.6228\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8006 - accuracy: 0.6964 - val_loss: 1.0379 - val_accuracy: 0.6360\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7965 - accuracy: 0.6913 - val_loss: 1.0353 - val_accuracy: 0.6447\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7947 - accuracy: 0.6913 - val_loss: 1.0168 - val_accuracy: 0.6667\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7968 - accuracy: 0.6984 - val_loss: 0.9960 - val_accuracy: 0.6689\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8015 - accuracy: 0.6901 - val_loss: 1.0301 - val_accuracy: 0.6469\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7841 - accuracy: 0.7025 - val_loss: 1.0168 - val_accuracy: 0.6425\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8110 - accuracy: 0.6879 - val_loss: 1.1259 - val_accuracy: 0.6228\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7919 - accuracy: 0.7067 - val_loss: 1.0694 - val_accuracy: 0.6360\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7920 - accuracy: 0.7030 - val_loss: 1.0708 - val_accuracy: 0.6360\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7965 - accuracy: 0.6981 - val_loss: 1.0664 - val_accuracy: 0.6360\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7982 - accuracy: 0.6930 - val_loss: 1.0572 - val_accuracy: 0.6338\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7999 - accuracy: 0.7008 - val_loss: 1.0519 - val_accuracy: 0.6469\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7929 - accuracy: 0.7052 - val_loss: 1.0317 - val_accuracy: 0.6513\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7720 - accuracy: 0.7050 - val_loss: 1.0448 - val_accuracy: 0.6491\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7903 - accuracy: 0.7033 - val_loss: 1.0579 - val_accuracy: 0.6382\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7597 - accuracy: 0.7152 - val_loss: 1.0337 - val_accuracy: 0.6535\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7738 - accuracy: 0.7074 - val_loss: 1.0441 - val_accuracy: 0.6404\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7604 - accuracy: 0.7140 - val_loss: 1.0363 - val_accuracy: 0.6469\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7782 - accuracy: 0.7042 - val_loss: 1.0474 - val_accuracy: 0.6360\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7738 - accuracy: 0.7084 - val_loss: 1.0558 - val_accuracy: 0.6447\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7598 - accuracy: 0.7140 - val_loss: 1.0376 - val_accuracy: 0.6447\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7644 - accuracy: 0.7030 - val_loss: 1.0276 - val_accuracy: 0.6579\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7613 - accuracy: 0.7123 - val_loss: 1.0248 - val_accuracy: 0.6535\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7727 - accuracy: 0.7057 - val_loss: 1.0229 - val_accuracy: 0.6469\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7903 - accuracy: 0.6962 - val_loss: 1.2033 - val_accuracy: 0.5658\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 0.7893 - accuracy: 0.6901 - val_loss: 1.0962 - val_accuracy: 0.6184\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7668 - accuracy: 0.7121 - val_loss: 1.0524 - val_accuracy: 0.6491\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7716 - accuracy: 0.7133 - val_loss: 1.0387 - val_accuracy: 0.6601\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 0.7846 - accuracy: 0.7038 - val_loss: 1.0101 - val_accuracy: 0.6623\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 0.7885 - accuracy: 0.7074 - val_loss: 1.0209 - val_accuracy: 0.6491\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7720 - accuracy: 0.7172 - val_loss: 1.0267 - val_accuracy: 0.6447\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7765 - accuracy: 0.7074 - val_loss: 1.0089 - val_accuracy: 0.6601\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7754 - accuracy: 0.7042 - val_loss: 1.0100 - val_accuracy: 0.6601\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7597 - accuracy: 0.7121 - val_loss: 1.0167 - val_accuracy: 0.6491\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 4s 62ms/step - loss: 0.7759 - accuracy: 0.7123 - val_loss: 1.0187 - val_accuracy: 0.6535\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7665 - accuracy: 0.7091 - val_loss: 1.0385 - val_accuracy: 0.6425\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7536 - accuracy: 0.7152 - val_loss: 1.0298 - val_accuracy: 0.6491\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7661 - accuracy: 0.7157 - val_loss: 1.0329 - val_accuracy: 0.6425\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7804 - accuracy: 0.7062 - val_loss: 1.0199 - val_accuracy: 0.6557\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7533 - accuracy: 0.7133 - val_loss: 1.0072 - val_accuracy: 0.6491\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7603 - accuracy: 0.7140 - val_loss: 1.0002 - val_accuracy: 0.6623\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7633 - accuracy: 0.7174 - val_loss: 1.0125 - val_accuracy: 0.6535\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7666 - accuracy: 0.7103 - val_loss: 1.0292 - val_accuracy: 0.6491\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7405 - accuracy: 0.7208 - val_loss: 1.0169 - val_accuracy: 0.6513\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7650 - accuracy: 0.7064 - val_loss: 1.1083 - val_accuracy: 0.6228\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.9277 - accuracy: 0.6591 - val_loss: 1.1436 - val_accuracy: 0.6272\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.7845 - accuracy: 0.7069 - val_loss: 1.0650 - val_accuracy: 0.6184\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7821 - accuracy: 0.7072 - val_loss: 1.0439 - val_accuracy: 0.6272\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7719 - accuracy: 0.7128 - val_loss: 1.0485 - val_accuracy: 0.6250\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7681 - accuracy: 0.7121 - val_loss: 1.0427 - val_accuracy: 0.6316\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7599 - accuracy: 0.7067 - val_loss: 1.0503 - val_accuracy: 0.6338\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7620 - accuracy: 0.7204 - val_loss: 1.0218 - val_accuracy: 0.6425\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7679 - accuracy: 0.7152 - val_loss: 1.0200 - val_accuracy: 0.6535\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7608 - accuracy: 0.7116 - val_loss: 1.0337 - val_accuracy: 0.6469\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7590 - accuracy: 0.7121 - val_loss: 1.0559 - val_accuracy: 0.6360\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7424 - accuracy: 0.7194 - val_loss: 1.0415 - val_accuracy: 0.6382\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7621 - accuracy: 0.7113 - val_loss: 1.0389 - val_accuracy: 0.6360\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7513 - accuracy: 0.7160 - val_loss: 1.0394 - val_accuracy: 0.6469\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.7483 - accuracy: 0.7179 - val_loss: 1.0365 - val_accuracy: 0.6469\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7585 - accuracy: 0.7167 - val_loss: 1.0501 - val_accuracy: 0.6382\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7551 - accuracy: 0.7118 - val_loss: 1.0511 - val_accuracy: 0.6360\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7533 - accuracy: 0.7184 - val_loss: 1.0608 - val_accuracy: 0.6272\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7474 - accuracy: 0.7233 - val_loss: 1.0501 - val_accuracy: 0.6272\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7661 - accuracy: 0.7140 - val_loss: 1.0456 - val_accuracy: 0.6360\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7485 - accuracy: 0.7213 - val_loss: 1.0389 - val_accuracy: 0.6447\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7431 - accuracy: 0.7252 - val_loss: 1.0337 - val_accuracy: 0.6425\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7506 - accuracy: 0.7133 - val_loss: 1.0442 - val_accuracy: 0.6294\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7599 - accuracy: 0.7252 - val_loss: 1.0481 - val_accuracy: 0.6294\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7518 - accuracy: 0.7211 - val_loss: 1.0272 - val_accuracy: 0.6425\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7331 - accuracy: 0.7179 - val_loss: 1.0327 - val_accuracy: 0.6404\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7461 - accuracy: 0.7238 - val_loss: 1.0264 - val_accuracy: 0.6491\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7311 - accuracy: 0.7235 - val_loss: 1.0247 - val_accuracy: 0.6491\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7475 - accuracy: 0.7121 - val_loss: 1.0431 - val_accuracy: 0.6404\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7514 - accuracy: 0.7199 - val_loss: 1.0729 - val_accuracy: 0.6272\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7413 - accuracy: 0.7177 - val_loss: 1.0667 - val_accuracy: 0.6294\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7336 - accuracy: 0.7225 - val_loss: 1.0508 - val_accuracy: 0.6316\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7284 - accuracy: 0.7284 - val_loss: 1.0215 - val_accuracy: 0.6382\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7325 - accuracy: 0.7238 - val_loss: 1.0517 - val_accuracy: 0.6360\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7391 - accuracy: 0.7199 - val_loss: 1.0372 - val_accuracy: 0.6447\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7479 - accuracy: 0.7189 - val_loss: 1.0182 - val_accuracy: 0.6404\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7400 - accuracy: 0.7167 - val_loss: 1.0311 - val_accuracy: 0.6425\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7538 - accuracy: 0.7189 - val_loss: 1.0480 - val_accuracy: 0.6206\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7287 - accuracy: 0.7323 - val_loss: 0.9944 - val_accuracy: 0.6425\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.8586 - accuracy: 0.6735 - val_loss: 1.0513 - val_accuracy: 0.6053\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7503 - accuracy: 0.7160 - val_loss: 1.0585 - val_accuracy: 0.6228\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7441 - accuracy: 0.7252 - val_loss: 1.0224 - val_accuracy: 0.6447\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7306 - accuracy: 0.7233 - val_loss: 1.0567 - val_accuracy: 0.6294\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7448 - accuracy: 0.7179 - val_loss: 1.0240 - val_accuracy: 0.6425\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7406 - accuracy: 0.7167 - val_loss: 1.0399 - val_accuracy: 0.6425\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7352 - accuracy: 0.7252 - val_loss: 1.0356 - val_accuracy: 0.6425\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7355 - accuracy: 0.7216 - val_loss: 1.0356 - val_accuracy: 0.6425\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7300 - accuracy: 0.7262 - val_loss: 1.0270 - val_accuracy: 0.6491\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7435 - accuracy: 0.7221 - val_loss: 1.0164 - val_accuracy: 0.6382\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7340 - accuracy: 0.7255 - val_loss: 0.9954 - val_accuracy: 0.6469\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7389 - accuracy: 0.7213 - val_loss: 0.9957 - val_accuracy: 0.6469\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7436 - accuracy: 0.7155 - val_loss: 1.0069 - val_accuracy: 0.6425\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7288 - accuracy: 0.7201 - val_loss: 1.0057 - val_accuracy: 0.6447\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7271 - accuracy: 0.7323 - val_loss: 1.0166 - val_accuracy: 0.6404\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7375 - accuracy: 0.7167 - val_loss: 1.0072 - val_accuracy: 0.6425\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7352 - accuracy: 0.7240 - val_loss: 1.0167 - val_accuracy: 0.6447\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7320 - accuracy: 0.7282 - val_loss: 1.0178 - val_accuracy: 0.6404\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.7297 - accuracy: 0.7235 - val_loss: 1.0084 - val_accuracy: 0.6469\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7367 - accuracy: 0.7174 - val_loss: 1.0814 - val_accuracy: 0.6096\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7283 - accuracy: 0.7277 - val_loss: 1.0539 - val_accuracy: 0.6118\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7271 - accuracy: 0.7277 - val_loss: 1.0267 - val_accuracy: 0.6250\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7288 - accuracy: 0.7269 - val_loss: 1.0187 - val_accuracy: 0.6294\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.7167 - accuracy: 0.7284 - val_loss: 1.0244 - val_accuracy: 0.6382\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7262 - accuracy: 0.7306 - val_loss: 1.0147 - val_accuracy: 0.6404\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7124 - accuracy: 0.7372 - val_loss: 1.0209 - val_accuracy: 0.6404\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7223 - accuracy: 0.7306 - val_loss: 1.0069 - val_accuracy: 0.6404\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7206 - accuracy: 0.7316 - val_loss: 1.0219 - val_accuracy: 0.6425\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7244 - accuracy: 0.7377 - val_loss: 1.0410 - val_accuracy: 0.6206\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7175 - accuracy: 0.7321 - val_loss: 1.0145 - val_accuracy: 0.6425\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7220 - accuracy: 0.7294 - val_loss: 1.0072 - val_accuracy: 0.6447\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.7313 - accuracy: 0.7216 - val_loss: 1.0130 - val_accuracy: 0.6447\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7320 - accuracy: 0.7247 - val_loss: 1.0523 - val_accuracy: 0.6184\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7200 - accuracy: 0.7265 - val_loss: 1.0528 - val_accuracy: 0.6338\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7225 - accuracy: 0.7311 - val_loss: 1.0184 - val_accuracy: 0.6513\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7183 - accuracy: 0.7282 - val_loss: 1.0074 - val_accuracy: 0.6447\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7198 - accuracy: 0.7308 - val_loss: 1.0152 - val_accuracy: 0.6491\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7150 - accuracy: 0.7362 - val_loss: 1.0323 - val_accuracy: 0.6382\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7193 - accuracy: 0.7313 - val_loss: 0.9933 - val_accuracy: 0.6820\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 4s 63ms/step - loss: 0.7259 - accuracy: 0.7306 - val_loss: 1.0042 - val_accuracy: 0.6491\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7045 - accuracy: 0.7338 - val_loss: 0.9989 - val_accuracy: 0.6513\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7301 - accuracy: 0.7277 - val_loss: 1.0084 - val_accuracy: 0.6469\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.7239 - accuracy: 0.7304 - val_loss: 1.0320 - val_accuracy: 0.6491\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe2e784c2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_,acc=model.evaluate(test_X,test_Y)\n",
        "print(acc*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxuf3OZVIy1b",
        "outputId": "1a2a579c-dc31-402b-cf59-e55e224627d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 14ms/step - loss: 1.0320 - accuracy: 0.6491\n",
            "64.91228342056274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Bengali Food Recognition/food_detector64.h5\")"
      ],
      "metadata": {
        "id": "f1MrFUa9I5mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "results={\n",
        "   0:'biryani',\n",
        "   1:'illish',\n",
        "   2:'misty',\n",
        "   3:'pitha',\n",
        "   4:'ruti'\n",
        "}\n",
        "\n",
        "# model = keras.models.load_model(\"/content/drive/MyDrive/Bengali Food Recognition/food_detector64.h5\")\n",
        "# for i in range(1, 2):\n",
        "#   im=Image.open(\"/content/drive/MyDrive/Bengali Food Recognition/test out of data/misty1.jpg\")\n",
        "# the input image is required to be in the shape of dataset, i.e (32,32,3)\n",
        "im=Image.open(\"/content/drive/MyDrive/Bengali Food Recognition/test out of data/misty1.jpg\")\n",
        "im=im.resize((64,64))\n",
        "print(np.array(im).shape)\n",
        "im=np.expand_dims(im,axis=0)\n",
        "im=np.array(im)\n",
        "print(im.shape)\n",
        "# pred=model.predict_classes([im])[0]\n",
        "predict_x=model.predict([im])\n",
        "classes_x=np.argmax(predict_x,axis=1)[0]  \n",
        "print(classes_x,\"----------\",results[classes_x])"
      ],
      "metadata": {
        "id": "nSzSl7RdI8ow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170fdfdf-a5ea-4456-81f6-40468baa5e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64, 3)\n",
            "(1, 64, 64, 3)\n",
            "1 ---------- illish\n"
          ]
        }
      ]
    }
  ]
}